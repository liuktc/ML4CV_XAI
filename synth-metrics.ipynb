{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:59:30.229536Z",
     "iopub.status.busy": "2025-03-29T15:59:30.229270Z",
     "iopub.status.idle": "2025-03-29T15:59:44.924692Z",
     "shell.execute_reply": "2025-03-29T15:59:44.923957Z",
     "shell.execute_reply.started": "2025-03-29T15:59:30.229508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ML4CV_XAI'...\n",
      "remote: Enumerating objects: 803, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 803 (delta 0), reused 7 (delta 0), pack-reused 789 (from 1)\u001b[K\n",
      "Receiving objects: 100% (803/803), 63.54 MiB | 39.20 MiB/s, done.\n",
      "Resolving deltas: 100% (353/353), done.\n",
      "Collecting captum\n",
      "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting grad_cam\n",
      "  Downloading grad-cam-1.5.4.tar.gz (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting Craft-xai\n",
      "  Downloading Craft_xai-0.0.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting torcheval\n",
      "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.5)\n",
      "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from captum) (24.2)\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from captum) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.67.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad_cam) (11.0.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad_cam) (0.20.1+cu121)\n",
      "Collecting ttach (from grad_cam)\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad_cam) (4.10.0.84)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad_cam) (1.2.2)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from Craft-xai) (0.25.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from Craft-xai) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0->captum) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0->captum) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0->captum) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0->captum) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0->captum) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0->captum) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->captum) (3.17.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->captum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->captum) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->captum) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->Craft-xai) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->Craft-xai) (2024.12.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->Craft-xai) (0.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad_cam) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad_cam) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0->captum) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0->captum) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0->captum) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0->captum) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0->captum) (2024.2.0)\n",
      "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Craft_xai-0.0.3-py3-none-any.whl (18 kB)\n",
      "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: grad_cam\n",
      "  Building wheel for grad_cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for grad_cam: filename=grad_cam-1.5.4-py3-none-any.whl size=39680 sha256=45ff896090d7259cd48a9f2c6f533badee2399779a17a4e1f1792d2b5d1f56ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/b0/82/1f97b5348c7fe9f0ce0ba18497202cafa5dec4562bd5292680\n",
      "Successfully built grad_cam\n",
      "Installing collected packages: ttach, torcheval, grad_cam, Craft-xai, captum\n",
      "Successfully installed Craft-xai-0.0.3 captum-0.8.0 grad_cam-1.5.4 torcheval-0.0.7 ttach-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./ML4CV_XAI\n",
    "!git clone https://github.com/liuktc/ML4CV_XAI.git\n",
    "!pip install captum grad_cam Craft-xai torcheval\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/ML4CV_XAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:59:48.735129Z",
     "iopub.status.busy": "2025-03-29T15:59:48.734839Z",
     "iopub.status.idle": "2025-03-29T15:59:54.472725Z",
     "shell.execute_reply": "2025-03-29T15:59:54.472029Z",
     "shell.execute_reply.started": "2025-03-29T15:59:48.735106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from models import vgg11_Syntetic, vgg_preprocess\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:59:57.822759Z",
     "iopub.status.busy": "2025-03-29T15:59:57.822296Z",
     "iopub.status.idle": "2025-03-29T16:00:04.774396Z",
     "shell.execute_reply": "2025-03-29T16:00:04.773713Z",
     "shell.execute_reply.started": "2025-03-29T15:59:57.822728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = vgg11_Syntetic().to(device)\n",
    "model.load_state_dict(torch.load(\"VGG11_Synthetic.pt\", map_location=device))\n",
    "preprocess = vgg_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T16:00:30.297324Z",
     "iopub.status.busy": "2025-03-29T16:00:30.296986Z",
     "iopub.status.idle": "2025-03-29T16:00:30.335703Z",
     "shell.execute_reply": "2025-03-29T16:00:30.334925Z",
     "shell.execute_reply.started": "2025-03-29T16:00:30.297296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from data import SynteticFigures, BlurImagePerlinNoise, Binarize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from models import vgg_preprocess\n",
    "\n",
    "TRAIN_SIZE = 8\n",
    "TEST_SIZE = 128\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "\n",
    "background_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.15, saturation=0.15, hue=0.15),\n",
    "])\n",
    "\n",
    "mask_preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST),\n",
    "        transforms.GaussianBlur(kernel_size=15),\n",
    "        transforms.ToTensor(),  # Convert to Tensor\n",
    "        Binarize(),\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.RandomResizedCrop(224),        # Random crop + resize\n",
    "    transforms.RandomHorizontalFlip(),        # Random flip\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3),    # Color variations\n",
    "    transforms.RandomRotation(15),            # Slight rotation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_train = SynteticFigures(background_path=\"./data/WaldoNoise\",\n",
    "                            num_images=TRAIN_SIZE,\n",
    "                            split='train',\n",
    "                            num_shapes_per_image=1,\n",
    "                            image_transform=train_transform,\n",
    "                            background_transform=background_transform,\n",
    "                            mask_preprocess=mask_preprocess,\n",
    "                            size_range=(80, 100))\n",
    "\n",
    "data_test = SynteticFigures(background_path=\"./data/WaldoNoise\",\n",
    "                            num_images=TEST_SIZE,\n",
    "                            split='test',\n",
    "                            num_shapes_per_image=1,\n",
    "                            image_transform=vgg_preprocess,\n",
    "                            background_transform=background_transform,\n",
    "                            mask_preprocess=mask_preprocess,\n",
    "                            size_range=(80, 100))\n",
    "\n",
    "\n",
    "train_dl = DataLoader(data_train, BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(data_test, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T16:01:00.062595Z",
     "iopub.status.busy": "2025-03-29T16:01:00.062262Z",
     "iopub.status.idle": "2025-03-29T16:01:14.494085Z",
     "shell.execute_reply": "2025-03-29T16:01:14.492839Z",
     "shell.execute_reply.started": "2025-03-29T16:01:00.062567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results loaded from ./results.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfffd3ffbe349fda8e6b48dae6503f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dabc037b4f4c8e90e859069c82fab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from metrics import calculate_metrics, ROC_AUC, RoadCombined, Sensitivity\n",
    "from results import ResultMetrics\n",
    "from utils import ERFUpsamplingFast, _GradCAMPlusPlus, _DeepLiftShap, ERFUpsampling, SimpleUpsampling\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "results = ResultMetrics(\"./results.csv\")\n",
    "\n",
    "for layer in tqdm(model.features[10:]):\n",
    "    # for attribution in [_GradCAMPlusPlus(model, layer), _DeepLiftShap()]:\n",
    "    for attribution in [_GradCAMPlusPlus(model, layer), _DeepLiftShap()]:\n",
    "        # for upsample in [ERFUpsamplingFast(model, layer, device), ERFUpsampling(model, layer, device), SimpleUpsampling((224,224)) ]:   \n",
    "        for upsample in [ERFUpsamplingFast(model, layer, device), SimpleUpsampling((224,224))]:   \n",
    "            calculate_metrics(model=model,\n",
    "                            attribute_method=attribution,\n",
    "                            test_dl=test_dl,\n",
    "                            train_dl=train_dl,\n",
    "                            layers=[layer],\n",
    "                            metrics=[ROC_AUC(), RoadCombined()],\n",
    "                            result_metrics=results,\n",
    "                            upsample=upsample,\n",
    "                            device=device,\n",
    "                            model_name=\"VGG11\",\n",
    "                            contains_mask=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:59:28.903536Z",
     "iopub.status.busy": "2025-03-22T12:59:28.903117Z",
     "iopub.status.idle": "2025-03-22T12:59:28.970217Z",
     "shell.execute_reply": "2025-03-22T12:59:28.969328Z",
     "shell.execute_reply.started": "2025-03-22T12:59:28.903493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zao\n"
     ]
    }
   ],
   "source": [
    "print(\"zao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 240133,
     "modelInstanceId": 246108,
     "sourceId": 307369,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
