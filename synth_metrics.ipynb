{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./ML4CV_XAI\n",
    "!git clone https://github.com/liuktc/ML4CV_XAI.git\n",
    "!pip install captum grad_cam Craft-xai torcheval\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/ML4CV_XAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from models import vgg11_Syntetic, vgg_preprocess\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg11_Syntetic().to(device)\n",
    "model.load_state_dict(torch.load(\"./VGG11_Synthetic.pt\", map_location=device))\n",
    "preprocess = vgg_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import SynteticFigures\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "TEST_SIZE = 2\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "class Binarize(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img:torch.Tensor):\n",
    "        # Sum over channels\n",
    "        img = img.sum(dim=0)\n",
    "        img[img > 0] = 1\n",
    "        img[img <= 0] = 0\n",
    "\n",
    "        return  img.unsqueeze(0)\n",
    "\n",
    "background_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "])\n",
    "\n",
    "mask_preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST),\n",
    "        transforms.GaussianBlur(kernel_size=15),\n",
    "        transforms.ToTensor(),  # Convert to Tensor\n",
    "        Binarize(),\n",
    "])\n",
    "\n",
    "data_test = SynteticFigures(background_path=\"./data/Waldo\",\n",
    "                            num_images=TEST_SIZE,\n",
    "                            split='test',\n",
    "                            num_shapes_per_image=1,\n",
    "                            image_transform=preprocess,\n",
    "                            background_transform=background_transform,\n",
    "                            mask_preprocess=mask_preprocess,\n",
    "                            num_other_shapes=0)\n",
    "\n",
    "data_train = SynteticFigures(background_path=\"./data/Waldo\",\n",
    "                            num_images=8,\n",
    "                            split='train',\n",
    "                            num_shapes_per_image=1,\n",
    "                            image_transform=preprocess,\n",
    "                            background_transform=background_transform,\n",
    "                            mask_preprocess=mask_preprocess,\n",
    "                            num_other_shapes=0)\n",
    "\n",
    "test_dl = DataLoader(data_test, BATCH_SIZE, shuffle=False)\n",
    "train_dl = DataLoader(data_train, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import calculate_metrics, ROC_AUC\n",
    "from results import ResultMetrics\n",
    "from utils import ERFUpsamplingFast, _GradCAMPlusPlus, _DeepLiftShap\n",
    "\n",
    "results = ResultMetrics(\"./results.csv\")\n",
    "\n",
    "for layer in model.features[10:]:\n",
    "    for attribution in [_GradCAMPlusPlus(model, layer), _DeepLiftShap()]:\n",
    "        for upsample in [ERFUpsamplingFast(model, layer, device)]:   \n",
    "            calculate_metrics(model=model,\n",
    "                            attribute_method=attribution,\n",
    "                            test_dl=test_dl,\n",
    "                            train_dl=train_dl,\n",
    "                            layers=[layer],\n",
    "                            metrics=[ROC_AUC()],\n",
    "                            result_metrics=results,\n",
    "                            upsample=upsample,\n",
    "                            device=device,\n",
    "                            model_name=\"VGG11\",\n",
    "                            contains_mask=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
